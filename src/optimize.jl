# module optimize

# export optimize

function optimize(pr; verbose::Bool=false, log::Bool=true, itrStart::Int64=1)
    # Initial settings
    dftol = pr.alg.dftol
    progress = pr.alg.progress
    maxiter = pr.alg.maxiter
    x0 = pr.x0
    x = x0
    fnext = 1e10
    fâ‚– = computeCost(pr, x0, getGradientToo=false)
    n = length(x)
    itr = 1
    fvals, Î±vals = [zeros(Float64, maxiter) for _ in 1:2]
    backtrackVals = zeros(Int64, maxiter, 1)
    xvals = zeros(Float64, n, maxiter)
    
    myprintln(verbose, "Begin with the solver:")
    
    while abs(fnext - fâ‚–) â‰¥ dftol && itr â‰¤ maxiter
        printOrNot = verbose && (itr % progress == 0)
        myprintln(printOrNot, "Iteration $(itr):", log=true)
        fâ‚–, âˆ‡fâ‚– = computeCost(pr, x)
        pâ‚– = findDirection(pr, âˆ‡fâ‚–)
        Î±, x, fnext, backtrackNum = linesearch(pr, x, pâ‚–, verbose=printOrNot, itrStart=itrStart)
        fvals[itr] = fnext
        Î±vals[itr] = Î±
        backtrackVals[itr] = backtrackNum
        xvals[:, itr] = x
        itr += 1
    end
    
    if itr > maxiter
        converged = false
        statusMessage = "Failed to converge despite $(maxiter) iterations! ðŸ˜¢"
        @warn statusMessage
    else
        converged = true
        statusMessage = "Convergence achieved in $(itr) iterations ðŸ˜„"
        println(statusMessage)
        # truncating arrays as they weren't filled to capacity
        fvals, Î±vals, backtrackVals, xvals = [arr[1:itr] for arr in (fvals, Î±vals, backtrackVals, xvals)]
    end
    
    res = (converged=converged, statusMessage=statusMessage, fvals=fvals, Î±vals=Î±vals, backtrackVals=backtrackVals, xvals=xvals)

    return res
end

"""
    findDirection(pr::NamedTuple, âˆ‡fnow::Vector{Float64}; verbose::Bool=false) -> Vector{Float64}

Compute the search direction for optimization methods based on the provided gradient `âˆ‡fnow` and the method specified in `pr.alg.method`.

# Arguments
- `pr::NamedTuple`: A named tuple containing problem configurations. Specifically, it must have `pr.alg.method` which defines the optimization method to be used.
- `âˆ‡fnow::Vector{Float64}`: The current gradient of the function to be optimized.

# Keyword Arguments
- `verbose::Bool=false`: Enables additional print statements for debugging and information purposes.

# Returns
- `Vector{Float64}`: The computed search direction.

# Example
```julia
pr = (alg=(method="GradientDescent", ...), ...)
gradient = [1.0, 2.0, 3.0]
direction = findDirection(pr, gradient)
"""
function findDirection(pr::NamedTuple, âˆ‡fnow::Vector{Float64};
    verbose::Bool=false)::Vector{Float64}
    method = pr.alg.method
    n = length(âˆ‡fnow)
    if method == "GradientDescent"
        # Bâ‚– = I(n)
        # pâ‚– = -Bâ‚–*âˆ‡fnow
        pâ‚– = -âˆ‡fnow
    else 
        @error "Currently not formulated for this method"
    end

    return pâ‚–
end

"""
    linesearch(pr::NamedTuple, xnow::Vector{Float64}, pâ‚–::Vector{Float64}; verbose::Bool=false)::Tuple{Float64, Vector{Float64}, Float64}

Performs line search to find an appropriate step size (`Î±`) that ensures the next parameter value `xnext` satisfies the specified conditions, and returns the objective function value `F` at that point.

# Arguments
- `pr::NamedTuple`: An object containing configurations, data, and algorithm settings.
- `xnow::Vector{Float64}`: The current values of the model parameters.
- `pâ‚–::Vector{Float64}`: The direction vector for the search.

# Keyword Arguments
- `verbose::Bool`: A flag for printing additional information during execution. Default is `false`.

# Returns
- A tuple containing:
    - `Î±`: The calculated step size.
    - `x`: The next parameter value `xnow + Î±*pâ‚–`.
    - `F`: The objective function value at `x`.

### Notes:
- The specific line search condition to use (e.g., "Armijo" or "StrongWolfe") is specified within the `pr` named tuple.
- This function primarily uses the Armijo condition to determine the step size. 
- It makes use of the `evaluateFunction` and `computeCost` functions.

# Example
```julia
pr = (alg=(linesearch="Armijo", c1=0.1, c2=0.9, ...), ...)
x_values = [1.0, 2.0, 3.0]
direction = [-0.5, -0.5, -0.5]
result = linesearch(pr, x_values, direction, verbose=false)
"""
function linesearch(pr::NamedTuple, xnow::Vector{Float64}, 
    pâ‚–::Vector{Float64};
    itrMax::Int64=50,
    itrStart::Int64=1,
    verbose::Bool=false,
    log::Bool=true)
    # f = Symbol(pr.objective)
    
    linesearch = pr.alg.linesearch
    câ‚ = pr.alg.c1
    câ‚‚ = pr.alg.c2
    Î² = 1/2^(itrStart-1)
    diff = Î²*pâ‚–
    xnext = xnow+diff
    fâ‚–, âˆ‡fâ‚– = computeCost(pr, xnow, verbose=verbose, log=log)
    fnext = fâ‚–
    itr_search_for_Î± = itrStart-1
    myprintln(verbose, "Current value of F, fâ‚– = $(fâ‚–)", log=log)
    armijoSatisfied = false
    strongWolfeSatisfied = false
    if linesearch == "StrongWolfe"
        while !strongWolfeSatisfied && itr_search_for_Î± â‰¤ itrMax
            diff = Î²*pâ‚–
            myprintln(false, "Let's shift x by $(diff)", log=log)
            xnext = xnow+diff
            fnext = computeCost(pr, xnext, getGradientToo=false)
            # println(câ‚*Î²*âˆ‡fâ‚–'*pâ‚–)
            myprintln(false, "To be compared against: $(fâ‚– + câ‚*Î²*âˆ‡fâ‚–'*pâ‚–)", log=log)
            if fnext â‰¤ fâ‚– + câ‚*Î²*âˆ‡fâ‚–'*pâ‚–
                myprintln(verbose, "Armijo condition satisfied for Î² = $(Î²)", log=log)
                fnext, âˆ‡fnext = computeCost(pr, xnext)
                if abs(âˆ‡fnext'*pâ‚–) â‰¥ abs(câ‚‚*âˆ‡fâ‚–'*pâ‚–)
                    myprintln(verbose, "Curvature condition satisfied for Î² = $(Î²)", log=log)
                    strongWolfeSatisfied = true
                else
                    itr_search_for_Î± += 1
                    myprintln(false, "Curvature condition NOT satisfied for Î² = $(Î²)", log=log)
                    Î² /= 2
                    myprintln(false, "Line Search Iterations = $(itr_search_for_Î±)", log=log)
                end
            else
                itr_search_for_Î± += 1
                myprintln(verbose, "Armijo condition NOT satisfied for Î² = $(Î²)", log=log)
                Î² /= 2
                myprintln(verbose, "Line Search Iterations = $(itr_search_for_Î±)", log=log)
            end 
        end
    elseif linesearch == "Armijo"
        # fâ‚–, âˆ‡fâ‚– = pr.objective( xnow, t)
        while !armijoSatisfied && itr_search_for_Î± â‰¤ itrMax
            diff = Î²*pâ‚–
            myprintln(verbose, "Let's shift x by $(diff)", log=log)
            xnext = xnow+diff
            fnext = computeCost(pr, xnext, getGradientToo=false)
            # println(câ‚*Î²*âˆ‡fâ‚–'*pâ‚–)
            myprintln(verbose, "To be compared against: $(fâ‚– + câ‚*Î²*âˆ‡fâ‚–'*pâ‚–)", log=log)
            if fnext â‰¤ fâ‚– + câ‚*Î²*âˆ‡fâ‚–'*pâ‚–
                myprintln(verbose, "Armijo condition satisfied for Î² = $(Î²)", log=log)
                armijoSatisfied = true
            else
                itr_search_for_Î± += 1
                myprintln(verbose, "Armijo condition NOT satisfied for Î² = $(Î²)", log=log)
                Î² /= 2
                myprintln(verbose, "Line Search Iterations = $(itr_search_for_Î±)", log=log)
            end 
        end
    else 
        @error "Unknown linesearch condition"
    end
    
    if itr_search_for_Î± > itrMax
        @error "Line Search failed at point x = $(xnext) despite $(itr_search_for_Î±) iterations."
    end

    Î± = Î²
    return (Î±=Î±, x=xnext, f=fnext, backtracks=itr_search_for_Î±) 
end

# end